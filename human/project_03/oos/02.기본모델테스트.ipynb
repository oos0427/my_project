{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GTP를 이용하여 ResNet50, efficientnet_b0 등 간단한 테스트 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터파일 불러오기 및 구성확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "path = \"Data/test_data_sets_02.pkl\"\n",
    "with open(path, \"rb\") as pickle_file:\n",
    "    test_data_sets = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 확인\n",
    "\n",
    "print(test_data_sets.keys())\n",
    "print(test_data_sets[\"Images\"].keys())\n",
    "print(test_data_sets[\"Metadata\"].keys())\n",
    "\n",
    "plt.imshow(test_data_sets[\"Images\"]['0002_03_F_01'])\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'info': {'filename': '0002_03_F.jpg',\n",
       "  'id': '0002',\n",
       "  'gender': 'F',\n",
       "  'age': 50,\n",
       "  'date': '2023-07-27',\n",
       "  'skin_type': 0,\n",
       "  'sensitive': 0},\n",
       " 'images': {'device': 2,\n",
       "  'width': 1920,\n",
       "  'height': 2560,\n",
       "  'angle': 0,\n",
       "  'facepart': 1,\n",
       "  'bbox': [788, 691, 1510, 1005]},\n",
       " 'annotations': {'forehead_pigmentation': 1, 'forehead_wrinkle': 1},\n",
       " 'equipment': {'forehead_moisture': 75.0,\n",
       "  'forehead_elasticity_R0': 0.287,\n",
       "  'forehead_elasticity_R1': 0.097,\n",
       "  'forehead_elasticity_R2': 0.662,\n",
       "  'forehead_elasticity_R3': 0.329,\n",
       "  'forehead_elasticity_R4': 0.135,\n",
       "  'forehead_elasticity_R5': 0.552,\n",
       "  'forehead_elasticity_R6': 0.649,\n",
       "  'forehead_elasticity_R7': 0.335,\n",
       "  'forehead_elasticity_R8': 0.19,\n",
       "  'forehead_elasticity_R9': 0.042,\n",
       "  'forehead_elasticity_Q0': 57.4,\n",
       "  'forehead_elasticity_Q1': 0.579,\n",
       "  'forehead_elasticity_Q2': 0.438,\n",
       "  'forehead_elasticity_Q3': 0.142}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_sets[\"Metadata\"]['0002_03_F_01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Distribution (Class Count):\n",
      "Class 0: 175\n",
      "Class 1: 443\n",
      "Class 2: 163\n",
      "Class 3: 69\n",
      "Class 4: 6\n",
      "Class 5: 2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAHHCAYAAABZbpmkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAy00lEQVR4nO3df3zN9f//8fuZ/cB+stiaZkOKiX6QWvUpsTZaJITylnqj3rXJj89b8smvvCs+VOtNoh+f6AfpXVKoSEO6ZH6W8iNCjGhDsvkxG9vz+0eXna9jIzuOnbNnt+vlci4X5/l8vs7r8Xq89d7d68eZwxhjBAAAYCk/bxcAAABwMRF2AACA1Qg7AADAaoQdAABgNcIOAACwGmEHAABYjbADAACsRtgBAABWI+wAAACrEXYAWKNNmzZq06ZNpezL4XBozJgxzvdjxoyRw+HQwYMHK2X/8fHxevDBBytlX0BVR9gBqhiHw3Fer2XLlnm7VBcrVqzQmDFjdPjw4fNa/+CDD7ocT0hIiBo2bKhu3bppzpw5Kikp8UpdlcmXawOqEn9vFwCgYt555x2X92+//bYWL15cZrxp06aVWdafWrFihZ5++mk9+OCDioiIOK9tgoKC9MYbb0iSCgoKlJ2drfnz56tbt25q06aNPvnkE4WFhTnXf/HFF5VSV2k9/v4X9/9Cz1Xb1q1b5efHv1eB80HYAaqYv/3tby7vV65cqcWLF5cZd4cxRidOnFCNGjUu+LM8wd/fv8xxPfPMMxo/fryGDx+u/v376/3333fOBQYGXtR6SkpKVFRUpOrVq6t69eoXdV9/JigoyKv7B6oS/lkAWGj69Olq27at6tatq6CgICUkJGjq1Kll1sXHx+uuu+7SokWL1KpVK9WoUUOvvvqqJCk7O1udOnVScHCw6tatq8GDB2vRokXlXiJbtWqV2rdvr/DwcNWsWVO33XabvvnmG+f8mDFjNHToUElSgwYNnJemdu3a5dbxPfnkk0pOTtYHH3ygn376yTle3j07kydPVrNmzVSzZk3VqlVLrVq10qxZs86rLofDofT0dM2cOVPNmjVTUFCQFi5c6Jw7/Z6dUgcPHlT37t0VFhamyMhIDRw4UCdOnHDO79q1Sw6HQzNmzCiz7emf+We1lXfPzs8//6x7771XtWvXVs2aNXXjjTfq008/dVmzbNkyORwO/ec//9Gzzz6ryy67TNWrV1e7du20ffv2s/YcqMo4swNYaOrUqWrWrJk6deokf39/zZ8/X4899phKSkqUlpbmsnbr1q2677779Mgjj6h///668sordezYMbVt21a//vqrBg4cqOjoaM2aNUtLly4ts68lS5aoQ4cOatmypUaPHi0/Pz9n2Pr666/VunVrdenSRT/99JPee+89ZWRk6JJLLpEk1alTx+1j7N27t7744gstXrxYV1xxRblrXn/9dT3++OPq1q2bM3T88MMPWrVqle6///7zqmvJkiX6z3/+o/T0dF1yySWKj48/Z13du3dXfHy8xo0bp5UrV2rSpEn6/fff9fbbb1fo+Cras9zcXN100006fvy4Hn/8cUVGRuqtt95Sp06d9OGHH+qee+5xWT9+/Hj5+fnpn//8p/Ly8jRhwgT16tVLq1atqlCdQJVgAFRpaWlp5sz/lI8fP15mXUpKimnYsKHLWFxcnJFkFi5c6DL+wgsvGEnm448/do4VFBSYJk2aGElm6dKlxhhjSkpKTOPGjU1KSoopKSlx2X+DBg3MHXfc4RybOHGikWR27tx5XsfVp08fExwcfNb57777zkgygwcPdo7ddttt5rbbbnO+v/vuu02zZs3OuZ9z1SXJ+Pn5mU2bNpU7N3r0aOf70aNHG0mmU6dOLusee+wxI8l8//33xhhjdu7caSSZ6dOn/+lnnqu2uLg406dPH+f7QYMGGUnm66+/do4dOXLENGjQwMTHx5vi4mJjjDFLly41kkzTpk1NYWGhc+2///1vI8ls2LChzL6Aqo7LWICFTr/nJi8vTwcPHtRtt92mn3/+WXl5eS5rGzRooJSUFJexhQsXql69eurUqZNzrHr16urfv7/LuvXr12vbtm26//779dtvv+ngwYM6ePCgjh07pnbt2mn58uUee2rqTCEhIZKkI0eOnHVNRESEfvnlF61Zs8bt/dx2221KSEg47/VnnjkbMGCAJOmzzz5zu4bz8dlnn6l169a65ZZbnGMhISF6+OGHtWvXLm3evNll/UMPPeRyj9N//dd/SfrjUhhgGy5jARb65ptvNHr0aGVlZen48eMuc3l5eQoPD3e+b9CgQZnts7Oz1ahRIzkcDpfxyy+/3OX9tm3bJEl9+vQ5ay15eXmqVatWhY/hzxw9elSSFBoaetY1w4YN05dffqnWrVvr8ssvV3Jysu6//37dfPPN572f8vpzLo0bN3Z536hRI/n5+bl9f9L5ys7O1g033FBmvPSpvOzsbF111VXO8fr167usK/3f6Pfff7+IVQLeQdgBLLNjxw61a9dOTZo00YsvvqjY2FgFBgbqs88+U0ZGRpkzLRfy5FXpZ02cOFHXXHNNuWtKz8B42saNGyWVDWCna9q0qbZu3aoFCxZo4cKFmjNnjl555RWNGjVKTz/99Hnt50KfTDszMJ75vlRxcfEF7aeiqlWrVu64MaZS6wAqA2EHsMz8+fNVWFioefPmufzrvbybi88mLi5OmzdvljHG5YfzmU/rNGrUSJIUFhampKSkc37m2X7Iu+udd96Rw+HQHXfccc51wcHB6tGjh3r06KGioiJ16dJFzz77rIYPH67q1at7vK5t27a5nA3avn27SkpKnDc2l55BOfOLArOzs8t8VkVqi4uL09atW8uMb9myxTkP/FVxzw5gmdJ/sZ/+L/S8vDxNnz79vD8jJSVFe/fu1bx585xjJ06c0Ouvv+6yrmXLlmrUqJGef/5552Wl0x04cMD55+DgYEllf8i7Y/z48friiy/Uo0ePMpeNTvfbb7+5vA8MDFRCQoKMMTp58qTH65KkKVOmuLyfPHmyJKlDhw6S/giGl1xyiZYvX+6y7pVXXinzWRWp7c4779Tq1auVlZXlHDt27Jhee+01xcfHV+i+I8A2nNkBLJOcnKzAwEB17NhRjzzyiI4eParXX39ddevW1a+//npen/HII4/o5Zdf1n333aeBAwfq0ksv1cyZM51fpFd6xsHPz09vvPGGOnTooGbNmumhhx5SvXr1tHfvXi1dulRhYWGaP3++pD+CkSQ99dRT6tmzpwICAtSxY0fnD/TynDp1Su+++66kP8JWdna25s2bpx9++EG33367XnvttT/tRXR0tG6++WZFRUXpxx9/1Msvv6zU1FTnvT7u1HUuO3fuVKdOndS+fXtlZWXp3Xff1f3336+rr77auaZfv34aP368+vXrp1atWmn58uUu3xdUqiK1Pfnkk3rvvffUoUMHPf7446pdu7beeust7dy5U3PmzOHblvHX5t2HwQBcqPIePZ83b55p0aKFqV69uomPjzf/+7//a958880yjzHHxcWZ1NTUcj/3559/NqmpqaZGjRqmTp065r//+7/NnDlzjCSzcuVKl7Xfffed6dKli4mMjDRBQUEmLi7OdO/e3WRmZrqs+9e//mXq1atn/Pz8/vQx9D59+hhJzlfNmjVNfHy86dq1q/nwww+dj1Kf7sxHz1999VVz6623Outq1KiRGTp0qMnLyzuvuiSZtLS0cuvTWR4937x5s+nWrZsJDQ01tWrVMunp6aagoMBl2+PHj5u+ffua8PBwExoaarp37272799f5jPPVduZj54bY8yOHTtMt27dTEREhKlevbpp3bq1WbBggcua0kfPP/jgA5fxcz0SD1R1DmO4Gw3A+XnppZc0ePBg/fLLL6pXr563ywGA80LYAVCugoIClyeRTpw4oWuvvVbFxcXlXnIBAF/FPTsAytWlSxfVr19f11xzjfLy8vTuu+9qy5YtmjlzprdLA4AKIewAKFdKSoreeOMNzZw5U8XFxUpISNDs2bPVo0cPb5cGABXCZSwAAGA1nkUEAABWI+wAAACrcc+O/vj9Pvv27VNoaKjHvzoeAABcHMYYHTlyRDExMef84kzCjqR9+/YpNjbW22UAAAA37NmzR5dddtlZ5wk7kvNr4/fs2aOwsDAvVwMAAM5Hfn6+YmNjnT/Hz4awo///e37CwsIIOwAAVDF/dgsKNygDAACrEXYAAIDVCDsAAMBqhB0AAGA1wg4AALAaYQcAAFiNsAMAAKxG2AEAAFYj7AAAAKsRdgAAgNUIOwAAwGqEHQAAYDXCDgAAsBphBwAAWI2wAwAArObv7QKA8sQ/+am3S/CKXeNTvV0CAFiHMzsAAMBqhB0AAGA1wg4AALAaYQcAAFiNsAMAAKxG2AEAAFYj7AAAAKsRdgAAgNUIOwAAwGqEHQAAYDXCDgAAsBphBwAAWI2wAwAArEbYAQAAViPsAAAAqxF2AACA1Qg7AADAaoQdAABgNcIOAACwGmEHAABYjbADAACsRtgBAABWI+wAAACrEXYAAIDVCDsAAMBqhB0AAGA1wg4AALAaYQcAAFiNsAMAAKzmM2Fn/PjxcjgcGjRokHPsxIkTSktLU2RkpEJCQtS1a1fl5ua6bLd7926lpqaqZs2aqlu3roYOHapTp05VcvUAAMBX+UTYWbNmjV599VW1aNHCZXzw4MGaP3++PvjgA3311Vfat2+funTp4pwvLi5WamqqioqKtGLFCr311luaMWOGRo0aVdmHAAAAfJTXw87Ro0fVq1cvvf7666pVq5ZzPC8vT//3f/+nF198UW3btlXLli01ffp0rVixQitXrpQkffHFF9q8ebPeffddXXPNNerQoYP+9a9/acqUKSoqKvLWIQEAAB/i9bCTlpam1NRUJSUluYyvW7dOJ0+edBlv0qSJ6tevr6ysLElSVlaWmjdvrqioKOealJQU5efna9OmTWfdZ2FhofLz811eAADATv7e3Pns2bP17bffas2aNWXmcnJyFBgYqIiICJfxqKgo5eTkONecHnRK50vnzmbcuHF6+umnL7B6AABQFXjtzM6ePXs0cOBAzZw5U9WrV6/UfQ8fPlx5eXnO1549eyp1/wAAoPJ4LeysW7dO+/fv13XXXSd/f3/5+/vrq6++0qRJk+Tv76+oqCgVFRXp8OHDLtvl5uYqOjpakhQdHV3m6azS96VryhMUFKSwsDCXFwAAsJPXwk67du20YcMGrV+/3vlq1aqVevXq5fxzQECAMjMzndts3bpVu3fvVmJioiQpMTFRGzZs0P79+51rFi9erLCwMCUkJFT6MQEAAN/jtXt2QkNDddVVV7mMBQcHKzIy0jnet29fDRkyRLVr11ZYWJgGDBigxMRE3XjjjZKk5ORkJSQkqHfv3powYYJycnI0YsQIpaWlKSgoqNKPCQAA+B6v3qD8ZzIyMuTn56euXbuqsLBQKSkpeuWVV5zz1apV04IFC/Too48qMTFRwcHB6tOnj8aOHevFqgEAgC9xGGOMt4vwtvz8fIWHhysvL4/7d3xE/JOfersEr9g1PtXbJQBAlXG+P7+9/j07AAAAFxNhBwAAWI2wAwAArEbYAQAAViPsAAAAqxF2AACA1Qg7AADAaoQdAABgNcIOAACwGmEHAABYjbADAACsRtgBAABWI+wAAACrEXYAAIDVCDsAAMBqhB0AAGA1wg4AALAaYQcAAFiNsAMAAKxG2AEAAFYj7AAAAKsRdgAAgNUIOwAAwGqEHQAAYDXCDgAAsBphBwAAWI2wAwAArEbYAQAAViPsAAAAqxF2AACA1Qg7AADAaoQdAABgNcIOAACwGmEHAABYjbADAACsRtgBAABWI+wAAACrEXYAAIDVCDsAAMBqhB0AAGA1wg4AALAaYQcAAFiNsAMAAKxG2AEAAFYj7AAAAKsRdgAAgNUIOwAAwGqEHQAAYDXCDgAAsBphBwAAWI2wAwAArEbYAQAAViPsAAAAqxF2AACA1Qg7AADAaoQdAABgNcIOAACwGmEHAABYjbADAACsRtgBAABWI+wAAACrEXYAAIDVCDsAAMBqhB0AAGA1wg4AALAaYQcAAFiNsAMAAKxG2AEAAFbzatiZOnWqWrRoobCwMIWFhSkxMVGff/65c/7EiRNKS0tTZGSkQkJC1LVrV+Xm5rp8xu7du5WamqqaNWuqbt26Gjp0qE6dOlXZhwIAAHyUV8POZZddpvHjx2vdunVau3at2rZtq7vvvlubNm2SJA0ePFjz58/XBx98oK+++kr79u1Tly5dnNsXFxcrNTVVRUVFWrFihd566y3NmDFDo0aN8tYhAQAAH+MwxhhvF3G62rVra+LEierWrZvq1KmjWbNmqVu3bpKkLVu2qGnTpsrKytKNN96ozz//XHfddZf27dunqKgoSdK0adM0bNgwHThwQIGBgee1z/z8fIWHhysvL09hYWEX7dhw/uKf/NTbJXjFrvGp3i4BAKqM8/357TP37BQXF2v27Nk6duyYEhMTtW7dOp08eVJJSUnONU2aNFH9+vWVlZUlScrKylLz5s2dQUeSUlJSlJ+f7zw7VJ7CwkLl5+e7vAAAgJ28HnY2bNigkJAQBQUF6R//+Ifmzp2rhIQE5eTkKDAwUBERES7ro6KilJOTI0nKyclxCTql86VzZzNu3DiFh4c7X7GxsZ49KAAA4DO8HnauvPJKrV+/XqtWrdKjjz6qPn36aPPmzRd1n8OHD1deXp7ztWfPnou6PwAA4D3+3i4gMDBQl19+uSSpZcuWWrNmjf7973+rR48eKioq0uHDh13O7uTm5io6OlqSFB0drdWrV7t8XunTWqVryhMUFKSgoCAPHwkAAPBFXj+zc6aSkhIVFhaqZcuWCggIUGZmpnNu69at2r17txITEyVJiYmJ2rBhg/bv3+9cs3jxYoWFhSkhIaHSawcAAL7Hq2d2hg8frg4dOqh+/fo6cuSIZs2apWXLlmnRokUKDw9X3759NWTIENWuXVthYWEaMGCAEhMTdeONN0qSkpOTlZCQoN69e2vChAnKycnRiBEjlJaWxpkbAAAgycthZ//+/XrggQf066+/Kjw8XC1atNCiRYt0xx13SJIyMjLk5+enrl27qrCwUCkpKXrllVec21erVk0LFizQo48+qsTERAUHB6tPnz4aO3astw4JAAD4GJ/7nh1v4Ht2fA/fswMA+DNV7nt2AAAALgbCDgAAsBphBwAAWI2wAwAArEbYAQAAViPsAAAAqxF2AACA1Qg7AADAaoQdAABgNcIOAACwGmEHAABYjbADAACsRtgBAABWI+wAAACrEXYAAIDVCDsAAMBqhB0AAGA1wg4AALAaYQcAAFiNsAMAAKxG2AEAAFYj7AAAAKsRdgAAgNUIOwAAwGqEHQAAYDXCDgAAsBphBwAAWI2wAwAArEbYAQAAVnMr7DRs2FC//fZbmfHDhw+rYcOGF1wUAACAp7gVdnbt2qXi4uIy44WFhdq7d+8FFwUAAOAp/hVZPG/ePOefFy1apPDwcOf74uJiZWZmKj4+3mPFAQAAXKgKhZ3OnTtLkhwOh/r06eMyFxAQoPj4eL3wwgseKw4AAOBCVSjslJSUSJIaNGigNWvW6JJLLrkoRQEAAHhKhcJOqZ07d3q6DgAAgIvCrbAjSZmZmcrMzNT+/fudZ3xKvfnmmxdcGAAAgCe4FXaefvppjR07Vq1atdKll14qh8Ph6boAAAA8wq2wM23aNM2YMUO9e/f2dD0AAAAe5db37BQVFemmm27ydC0AAAAe51bY6devn2bNmuXpWgAAADzOrctYJ06c0GuvvaYvv/xSLVq0UEBAgMv8iy++6JHiAAAALpRbYeeHH37QNddcI0nauHGjyxw3KwMAAF/iVthZunSpp+sAAAC4KNy6ZwcAAKCqcOvMzu23337Oy1VLlixxuyAAAABPcivslN6vU+rkyZNav369Nm7cWOYXhAIAAHiTW2EnIyOj3PExY8bo6NGjF1QQAACAJ3n0np2//e1v/F4sAADgUzwadrKyslS9enVPfiQAAMAFcesyVpcuXVzeG2P066+/au3atRo5cqRHCgMAAPAEt8JOeHi4y3s/Pz9deeWVGjt2rJKTkz1SGAAAgCe4FXamT5/u6ToAAAAuCrfCTql169bpxx9/lCQ1a9ZM1157rUeKAgAA8BS3ws7+/fvVs2dPLVu2TBEREZKkw4cP6/bbb9fs2bNVp04dT9YIAADgNreexhowYICOHDmiTZs26dChQzp06JA2btyo/Px8Pf74456uEQAAwG1undlZuHChvvzySzVt2tQ5lpCQoClTpnCDMgAA8ClundkpKSlRQEBAmfGAgACVlJRccFEAAACe4lbYadu2rQYOHKh9+/Y5x/bu3avBgwerXbt2HisOAADgQrkVdl5++WXl5+crPj5ejRo1UqNGjdSgQQPl5+dr8uTJnq4RAADAbW7dsxMbG6tvv/1WX375pbZs2SJJatq0qZKSkjxaHAAAwIWq0JmdJUuWKCEhQfn5+XI4HLrjjjs0YMAADRgwQNdff72aNWumr7/++mLVCgAAUGEVCjsvvfSS+vfvr7CwsDJz4eHheuSRR/Tiiy96rDgAAIALVaGw8/3336t9+/ZnnU9OTta6desuuCgAAABPqVDYyc3NLfeR81L+/v46cODABRcFAADgKRUKO/Xq1dPGjRvPOv/DDz/o0ksvveCiAAAAPKVCYefOO+/UyJEjdeLEiTJzBQUFGj16tO666y6PFQcAAHChKvTo+YgRI/TRRx/piiuuUHp6uq688kpJ0pYtWzRlyhQVFxfrqaeeuiiFAgAAuKNCYScqKkorVqzQo48+quHDh8sYI0lyOBxKSUnRlClTFBUVdVEKBQAAcEeFv1QwLi5On332mX7//Xdt375dxhg1btxYtWrVuhj1AQAAXBC3fl2EJNWqVUvXX3+9Wrdu7XbQGTdunK6//nqFhoaqbt266ty5s7Zu3eqy5sSJE0pLS1NkZKRCQkLUtWtX5ebmuqzZvXu3UlNTVbNmTdWtW1dDhw7VqVOn3D00AABgEbfDjid89dVXSktL08qVK7V48WKdPHlSycnJOnbsmHPN4MGDNX/+fH3wwQf66quvtG/fPnXp0sU5X1xcrNTUVBUVFWnFihV66623NGPGDI0aNcobhwQAAHyMw5TeeOMDDhw4oLp16+qrr77Srbfeqry8PNWpU0ezZs1St27dJP1xM3TTpk2VlZWlG2+8UZ9//rnuuusu7du3z3m/0LRp0zRs2DAdOHBAgYGBf7rf/Px8hYeHKy8vr9xvh0bli3/yU2+X4BW7xqd6uwQAqDLO9+e3V8/snCkvL0+SVLt2bUnSunXrdPLkSZdfMNqkSRPVr19fWVlZkqSsrCw1b97c5cbolJQU5efna9OmTeXup7CwUPn5+S4vAABgJ58JOyUlJRo0aJBuvvlmXXXVVZKknJwcBQYGKiIiwmVtVFSUcnJynGvOfAKs9H3pmjONGzdO4eHhzldsbKyHjwYAAPgKnwk7aWlp2rhxo2bPnn3R9zV8+HDl5eU5X3v27Lno+wQAAN5R4UfPL4b09HQtWLBAy5cv12WXXeYcj46OVlFRkQ4fPuxydic3N1fR0dHONatXr3b5vNKntUrXnCkoKEhBQUEePgoAAOCLvHpmxxij9PR0zZ07V0uWLFGDBg1c5lu2bKmAgABlZmY6x7Zu3ardu3crMTFRkpSYmKgNGzZo//79zjWLFy9WWFiYEhISKudAAACAz/LqmZ20tDTNmjVLn3zyiUJDQ5332ISHh6tGjRoKDw9X3759NWTIENWuXVthYWEaMGCAEhMTdeONN0qSkpOTlZCQoN69e2vChAnKycnRiBEjlJaWxtkbAADg3bAzdepUSVKbNm1cxqdPn64HH3xQkpSRkSE/Pz917dpVhYWFSklJ0SuvvOJcW61aNS1YsECPPvqoEhMTFRwcrD59+mjs2LGVdRgAAMCH+dT37HgL37Pje/ieHQDAn6mS37MDAADgaYQdAABgNcIOAACwGmEHAABYjbADAACsRtgBAABWI+wAAACrEXYAAIDVCDsAAMBqhB0AAGA1wg4AALAaYQcAAFiNsAMAAKzm7+0CbMdv7wYAwLs4swMAAKxG2AEAAFYj7AAAAKsRdgAAgNUIOwAAwGqEHQAAYDXCDgAAsBphBwAAWI0vFQQswpdYAkBZnNkBAABWI+wAAACrEXYAAIDVCDsAAMBqhB0AAGA1wg4AALAaYQcAAFiNsAMAAKxG2AEAAFYj7AAAAKsRdgAAgNUIOwAAwGqEHQAAYDXCDgAAsBphBwAAWI2wAwAArEbYAQAAViPsAAAAqxF2AACA1Qg7AADAaoQdAABgNcIOAACwGmEHAABYjbADAACsRtgBAABWI+wAAACrEXYAAIDVCDsAAMBqhB0AAGA1wg4AALAaYQcAAFiNsAMAAKxG2AEAAFYj7AAAAKsRdgAAgNUIOwAAwGqEHQAAYDXCDgAAsBphBwAAWI2wAwAArEbYAQAAViPsAAAAqxF2AACA1Qg7AADAaoQdAABgNa+GneXLl6tjx46KiYmRw+HQxx9/7DJvjNGoUaN06aWXqkaNGkpKStK2bdtc1hw6dEi9evVSWFiYIiIi1LdvXx09erQSjwIAAPgyr4adY8eO6eqrr9aUKVPKnZ8wYYImTZqkadOmadWqVQoODlZKSopOnDjhXNOrVy9t2rRJixcv1oIFC7R8+XI9/PDDlXUIAADAx/l7c+cdOnRQhw4dyp0zxuill17SiBEjdPfdd0uS3n77bUVFRenjjz9Wz5499eOPP2rhwoVas2aNWrVqJUmaPHmy7rzzTj3//POKiYmptGMBAAC+yWfv2dm5c6dycnKUlJTkHAsPD9cNN9ygrKwsSVJWVpYiIiKcQUeSkpKS5Ofnp1WrVp31swsLC5Wfn+/yAgAAdvLZsJOTkyNJioqKchmPiopyzuXk5Khu3bou8/7+/qpdu7ZzTXnGjRun8PBw5ys2NtbD1QMAAF/hs2HnYho+fLjy8vKcrz179ni7JAAAcJH4bNiJjo6WJOXm5rqM5+bmOueio6O1f/9+l/lTp07p0KFDzjXlCQoKUlhYmMsLAADYyWfDToMGDRQdHa3MzEznWH5+vlatWqXExERJUmJiog4fPqx169Y51yxZskQlJSW64YYbKr1mAADge7z6NNbRo0e1fft25/udO3dq/fr1ql27turXr69BgwbpmWeeUePGjdWgQQONHDlSMTEx6ty5sySpadOmat++vfr3769p06bp5MmTSk9PV8+ePXkSCwAASPJy2Fm7dq1uv/125/shQ4ZIkvr06aMZM2boiSee0LFjx/Twww/r8OHDuuWWW7Rw4UJVr17duc3MmTOVnp6udu3ayc/PT127dtWkSZMq/VgAAIBv8mrYadOmjYwxZ513OBwaO3asxo4de9Y1tWvX1qxZsy5GeQAAwAI+e88OAACAJxB2AACA1Qg7AADAaoQdAABgNcIOAACwGmEHAABYjbADAACsRtgBAABWI+wAAACrEXYAAIDVCDsAAMBqhB0AAGA1wg4AALAaYQcAAFiNsAMAAKxG2AEAAFYj7AAAAKsRdgAAgNX8vV0AAHhT/JOfersEr9k1PtXbJQCVgjM7AADAaoQdAABgNcIOAACwGmEHAABYjbADAACsRtgBAABWI+wAAACrEXYAAIDVCDsAAMBqhB0AAGA1wg4AALAaYQcAAFiNsAMAAKxG2AEAAFYj7AAAAKsRdgAAgNUIOwAAwGqEHQAAYDXCDgAAsBphBwAAWI2wAwAArEbYAQAAViPsAAAAqxF2AACA1Qg7AADAaoQdAABgNcIOAACwGmEHAABYjbADAACsRtgBAABWI+wAAACrEXYAAIDVCDsAAMBqhB0AAGA1wg4AALAaYQcAAFiNsAMAAKxG2AEAAFYj7AAAAKsRdgAAgNUIOwAAwGqEHQAAYDXCDgAAsBphBwAAWI2wAwAArEbYAQAAViPsAAAAqxF2AACA1Qg7AADAav7eLsBTpkyZookTJyonJ0dXX321Jk+erNatW3u7LACwUvyTn3q7BK/YNT7V2yXADVac2Xn//fc1ZMgQjR49Wt9++62uvvpqpaSkaP/+/d4uDQAAeJkVYefFF19U//799dBDDykhIUHTpk1TzZo19eabb3q7NAAA4GVV/jJWUVGR1q1bp+HDhzvH/Pz8lJSUpKysLC9WBgCAKy7/eUeVDzsHDx5UcXGxoqKiXMajoqK0ZcuWcrcpLCxUYWGh831eXp4kKT8/3+P1lRQe9/hnVgUX2kv65h76VnF/1Z5J9M0d/Dfqnovx8/X0zzXGnHNdlQ877hg3bpyefvrpMuOxsbFeqMZO4S95u4Kqib65h765h75VHD1zz8Xu25EjRxQeHn7W+Sofdi655BJVq1ZNubm5LuO5ubmKjo4ud5vhw4dryJAhzvclJSU6dOiQIiMj5XA4Lmq9lSU/P1+xsbHas2ePwsLCvF1OlUHf3EPf3EPfKo6eucfWvhljdOTIEcXExJxzXZUPO4GBgWrZsqUyMzPVuXNnSX+El8zMTKWnp5e7TVBQkIKCglzGIiIiLnKl3hEWFmbVX+zKQt/cQ9/cQ98qjp65x8a+neuMTqkqH3YkaciQIerTp49atWql1q1b66WXXtKxY8f00EMPebs0AADgZVaEnR49eujAgQMaNWqUcnJydM0112jhwoVlbloGAAB/PVaEHUlKT08/62Wrv6KgoCCNHj26zOU6nBt9cw99cw99qzh65p6/et8c5s+e1wIAAKjCrPgGZQAAgLMh7AAAAKsRdgAAgNUIO1WAw+HQxx9/7O0yqhz65h765h76VnH0zD30reIIO16Wk5OjAQMGqGHDhgoKClJsbKw6duyozMxMb5cm6Y9vpxw1apQuvfRS1ahRQ0lJSdq2bZu3y/L5vn300UdKTk52fiv3+vXrvV2SJN/u28mTJzVs2DA1b95cwcHBiomJ0QMPPKB9+/Z5uzSf7pskjRkzRk2aNFFwcLBq1aqlpKQkrVq1yqs1+XrPTvePf/xDDodDL730krdL8fm+Pfjgg3I4HC6v9u3be7usP2XNo+dV0a5du3TzzTcrIiJCEydOVPPmzXXy5EktWrRIaWlpZ/1FppVpwoQJmjRpkt566y01aNBAI0eOVEpKijZv3qzq1at7paaq0Ldjx47plltuUffu3dW/f39vlyPJ9/t2/Phxffvttxo5cqSuvvpq/f777xo4cKA6deqktWvXeq0uX++bJF1xxRV6+eWX1bBhQxUUFCgjI0PJycnavn276tSpU+n1VIWelZo7d65Wrlz5p79uoDJUlb61b99e06dPd76vEo+zG3hNhw4dTL169czRo0fLzP3+++/OP0syc+fOdb5/4oknTOPGjU2NGjVMgwYNzIgRI0xRUZFzfv369aZNmzYmJCTEhIaGmuuuu86sWbPGGGPMrl27zF133WUiIiJMzZo1TUJCgvn000/Lra+kpMRER0ebiRMnOscOHz5sgoKCzHvvvXeBR+8+X+/b6Xbu3Gkkme+++87t4/WUqtS3UqtXrzaSTHZ2dsUP2EOqYt/y8vKMJPPll19W/IA9oKr07JdffjH16tUzGzduNHFxcSYjI+OCjvtCVYW+9enTx9x9990XfKyVjTM7XnLo0CEtXLhQzz77rIKDg8vMn+t3dYWGhmrGjBmKiYnRhg0b1L9/f4WGhuqJJ56QJPXq1UvXXnutpk6dqmrVqmn9+vUKCAiQJKWlpamoqEjLly9XcHCwNm/erJCQkHL3s3PnTuXk5CgpKck5Fh4erhtuuEFZWVnq2bPnBXTAPVWhb76oqvYtLy9PDofDa7+7rir2raioSK+99prCw8N19dVXV/ygL1BV6VlJSYl69+6toUOHqlmzZhd20B5QVfomScuWLVPdunVVq1YttW3bVs8884wiIyPdP/jK4O209Ve1atUqI8l89NFHf7pWZ6T4M02cONG0bNnS+T40NNTMmDGj3LXNmzc3Y8aMOa8av/nmGyPJ7Nu3z2X83nvvNd27dz+vz/C0qtC30/nKmZ2q1jdjjCkoKDDXXXeduf/++93a3hOqUt/mz59vgoODjcPhMDExMWb16tUV2t5TqkrPnnvuOXPHHXeYkpISY4zx+pmdqtK39957z3zyySfmhx9+MHPnzjVNmzY1119/vTl16tR5f4Y3EHa8ZOXKlW7/xZ49e7a56aabTFRUlAkODjZBQUGmTp06zvnRo0cbf39/065dOzNu3Dizfft259zrr79u/P39zU033WRGjRplvv/++7Pu1xfDTlXo2+l8JexUtb4VFRWZjh07mmuvvdbk5eWd/4F6WFXq29GjR822bdtMVlaW+fvf/27i4+NNbm5uxQ7YA6pCz9auXWuioqLM3r17nWPeDjtVoW/l2bFjh1cvmZ4vwo6X/Pbbb8bhcJjnnnvuT9ee/hd7xYoVplq1auaZZ54xa9asMT/99JMZO3asCQ8Pd9lm69at5sUXXzR33HGHCQwMdPkPaPfu3Wbq1KnmnnvuMQEBAWbSpEnl7rf0L/GZP6hvvfVW8/jjj1foeD2lKvTtdL4SdqpS34qKikznzp1NixYtzMGDByt8rJ5Ulfp2pssvv/y86va0qtCzjIwM43A4TLVq1ZwvScbPz8/ExcW5e+gXpCr07WwuueQSM23atAptU9kIO17Uvn37Ct+M9vzzz5uGDRu6rO3bt2+Zv9in69mzp+nYsWO5c08++aRp3rx5uXOlNyg///zzzrG8vDyv36Ds6307na+EHWOqRt9Kg06zZs3M/v37z34wlagq9K08DRs2NKNHj67QNp7i6z07ePCg2bBhg8srJibGDBs2zGzZsuXcB3cR+XrfyrNnzx7jcDjMJ598ct7beAPfs+NFU6ZMUXFxsVq3bq05c+Zo27Zt+vHHHzVp0iQlJiaWu03jxo21e/duzZ49Wzt27NCkSZM0d+5c53xBQYHS09O1bNkyZWdn65tvvtGaNWvUtGlTSdKgQYO0aNEi7dy5U99++62WLl3qnDuTw+HQoEGD9Mwzz2jevHnasGGDHnjgAcXExKhz584e78f58vW+SX/cbLh+/Xpt3rxZkrR161atX79eOTk5HuxExfh6306ePKlu3bpp7dq1mjlzpoqLi5WTk6OcnBwVFRV5viHnydf7duzYMf3P//yPVq5cqezsbK1bt05///vftXfvXt17772eb8h58PWeRUZG6qqrrnJ5BQQEKDo6WldeeaXnG3KefL1vR48e1dChQ7Vy5Urt2rVLmZmZuvvuu3X55ZcrJSXF8w3xJG+nrb+6ffv2mbS0NBMXF2cCAwNNvXr1TKdOnczSpUuda3TG9dmhQ4eayMhIExISYnr06GEyMjKcKb6wsND07NnTxMbGmsDAQBMTE2PS09NNQUGBMcaY9PR006hRI+c13d69e5/zUkFJSYkZOXKkiYqKMkFBQaZdu3Zm69atF6MVFeLrfZs+fbqRVOblrX9pl/LlvpWeBSvvdXp93uDLfSsoKDD33HOPiYmJMYGBgebSSy81nTp18toNyqV8uWfl8fY9O6V8uW/Hjx83ycnJpk6dOiYgIMDExcWZ/v37m5ycnIvVDo9xGGNMpScsAACASsJlLAAAYDXCDgAAsBphBwAAWI2wAwAArEbYAQAAViPsAAAAqxF2AACA1Qg7AHyew+HQxx9/7O0yAFRRhB0AXpeTk6MBAwaoYcOGCgoKUmxsrDp27KjMzExvlwbAAv7eLgDAX9uuXbt08803KyIiQhMnTlTz5s118uRJLVq0SGlpadqyZYu3SwRQxXFmB4BXPfbYY3I4HFq9erW6du2qK664Qs2aNdOQIUO0cuXKcrcZNmyYrrjiCtWsWVMNGzbUyJEjdfLkSef8999/r9tvv12hoaEKCwtTy5YttXbtWklSdna2OnbsqFq1aik4OFjNmjXTZ5995tx248aN6tChg0JCQhQVFaXevXvr4MGDzvkPP/xQzZs3V40aNRQZGamkpCQdO3bsInUHgCdwZgeA1xw6dEgLFy7Us88+q+Dg4DLzERER5W4XGhqqGTNmKCYmRhs2bFD//v0VGhqqJ554QpLUq1cvXXvttZo6daqqVaum9evXKyAgQJKUlpamoqIiLV++XMHBwdq8ebNCQkIkSYcPH1bbtm3Vr18/ZWRkqKCgQMOGDVP37t21ZMkS/frrr7rvvvs0YcIE3XPPPTpy5Ii+/vpr8SsGAd9G2AHgNdu3b5cxRk2aNKnQdiNGjHD+OT4+Xv/85z81e/ZsZ9jZvXu3hg4d6vzcxo0bO9fv3r1bXbt2VfPmzSVJDRs2dM69/PLLuvbaa/Xcc885x958803Fxsbqp59+0tGjR3Xq1Cl16dJFcXFxkuT8HAC+i7ADwGvcPSPy/vvva9KkSdqxY4czgISFhTnnhwwZon79+umdd95RUlKS7r33XjVq1EiS9Pjjj+vRRx/VF198oaSkJHXt2lUtWrSQ9Mflr6VLlzrP9Jxux44dSk5OVrt27dS8eXOlpKQoOTlZ3bp1U61atdw6DgCVg3t2AHhN48aN5XA4KnQTclZWlnr16qU777xTCxYs0HfffaennnpKRUVFzjVjxozRpk2blJqaqiVLlighIUFz586VJPXr108///yzevfurQ0bNqhVq1aaPHmyJOno0aPq2LGj1q9f7/Latm2bbr31VlWrVk2LFy/W559/roSEBE2ePFlXXnmldu7c6dnGAPAoh+FiMwAv6tChgzZs2KCtW7eWuW/n8OHDioiIkMPh0Ny5c9W5c2e98MILeuWVV7Rjxw7nun79+unDDz/U4cOHy93Hfffdp2PHjmnevHll5oYPH65PP/1UP/zwg5566inNmTNHGzdulL//n5/4Li4uVlxcnIYMGaIhQ4ZU7MABVBrO7ADwqilTpqi4uFitW7fWnDlztG3bNv3444+aNGmSEhMTy6xv3Lixdu/erdmzZ2vHjh2aNGmS86yNJBUUFCg9PV3Lli1Tdna2vvnmG61Zs0ZNmzaVJA0aNEiLFi3Szp079e2332rp0qXOubS0NB06dEj33Xef1qxZox07dmjRokV66KGHVFxcrFWrVum5557T2rVrtXv3bn300Uc6cOCAc3sAPsoAgJft27fPpKWlmbi4OBMYGGjq1atnOnXqZJYuXWqMMUaSmTt3rnP90KFDTWRkpAkJCTE9evQwGRkZJjw83BhjTGFhoenZs6eJjY01gYGBJiYmxqSnp5uCggJjjDHp6emmUaNGJigoyNSpU8f07t3bHDx40PnZP/30k7nnnntMRESEqVGjhmnSpIkZNGiQKSkpMZs3bzYpKSmmTp06JigoyFxxxRVm8uTJldUmAG7iMhYAALAal7EAAIDVCDsAAMBqhB0AAGA1wg4AALAaYQcAAFiNsAMAAKxG2AEAAFYj7AAAAKsRdgAAgNUIOwAAwGqEHQAAYDXCDgAAsNr/A2RVmshdPCEUAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# 전체 데이터셋의 타겟 분포 확인\n",
    "targets = [metadata[\"annotations\"][\"forehead_pigmentation\"] for metadata in test_data_sets[\"Metadata\"].values()]\n",
    "target_distribution = Counter(targets)\n",
    "\n",
    "# 분포 출력\n",
    "print(\"Target Distribution (Class Count):\")\n",
    "for target, count in sorted(target_distribution.items()):\n",
    "    print(f\"Class {target}: {count}\")\n",
    "\n",
    "# 시각화를 위한 matplotlib 사용\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "classes = sorted(target_distribution.keys())\n",
    "counts = [target_distribution[c] for c in classes]\n",
    "\n",
    "plt.bar(classes, counts, tick_label=[f\"Class {c}\" for c in classes])\n",
    "plt.xlabel(\"Classes\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Target Distribution\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>대략적인 양상을 보기 위한 선행 모델학습</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 1.3547, Train Accuracy: 46.50%\n",
      "Validation Accuracy: 9.88%\n",
      "Epoch 2/10, Loss: 1.1175, Train Accuracy: 51.31%\n",
      "Validation Accuracy: 25.00%\n",
      "Epoch 3/10, Loss: 1.0445, Train Accuracy: 52.77%\n",
      "Validation Accuracy: 56.40%\n",
      "Epoch 4/10, Loss: 1.0050, Train Accuracy: 58.60%\n",
      "Validation Accuracy: 37.79%\n",
      "Epoch 5/10, Loss: 0.9645, Train Accuracy: 56.27%\n",
      "Validation Accuracy: 44.77%\n",
      "Epoch 6/10, Loss: 0.9581, Train Accuracy: 59.77%\n",
      "Validation Accuracy: 57.56%\n",
      "Epoch 7/10, Loss: 0.9834, Train Accuracy: 57.43%\n",
      "Validation Accuracy: 48.84%\n",
      "Epoch 8/10, Loss: 0.9383, Train Accuracy: 60.20%\n",
      "Validation Accuracy: 48.26%\n",
      "Epoch 9/10, Loss: 0.8833, Train Accuracy: 62.10%\n",
      "Validation Accuracy: 51.74%\n",
      "Epoch 10/10, Loss: 0.8018, Train Accuracy: 65.45%\n",
      "Validation Accuracy: 46.51%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "\n",
    "# Dataset 클래스 정의\n",
    "class SkinDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.images = data[\"Images\"]  # Images: numpy.ndarray 형태로 저장된 이미지들\n",
    "        self.metadata = data[\"Metadata\"]  # Metadata: JSON 메타데이터\n",
    "        self.transform = transform\n",
    "        self.keys = list(self.metadata.keys())  # 데이터 키 리스트\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.keys)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        key = self.keys[idx]\n",
    "        image_data = self.images[key]  # numpy.ndarray 이미지 데이터\n",
    "        metadata = self.metadata[key]  # 메타데이터\n",
    "        \n",
    "        # numpy.ndarray 이미지를 PIL 이미지로 변환\n",
    "        image = Image.fromarray(image_data)\n",
    "        \n",
    "        # 타겟 레이블 (forehead_pigmentation)\n",
    "        target = metadata[\"annotations\"][\"forehead_pigmentation\"]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, target\n",
    "\n",
    "# 이미지 전처리\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # ResNet50 입력 크기에 맞춤\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # ResNet50 사전 학습 기준\n",
    "])\n",
    "\n",
    "# Dataset 및 Train/Validation Split\n",
    "dataset = SkinDataset(test_data_sets, transform=transform)  # test_data_sets는 이미 로드된 상태로 사용\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# ResNet50 모델 로드 및 수정\n",
    "model = models.resnet50(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, 6)  # 출력 클래스 수를 6으로 수정 (0~5)\n",
    "\n",
    "# 손실 함수 및 옵티마이저\n",
    "criterion = nn.CrossEntropyLoss()  # 분류 문제에 적합한 손실 함수\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # 학습률 0.001\n",
    "\n",
    "# GPU/CPU 장치 설정\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# 학습 및 검증 루프\n",
    "num_epochs = 10  # 에포크 수\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    \n",
    "    for images, targets in train_loader:\n",
    "        images, targets = images.to(device), targets.to(device)\n",
    "        \n",
    "        # 옵티마이저 초기화\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 모델 출력 및 손실 계산\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # 역전파 및 가중치 업데이트\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_train += (predicted == targets).sum().item()\n",
    "        total_train += targets.size(0)\n",
    "    \n",
    "    train_accuracy = correct_train / total_train * 100\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader):.4f}, Train Accuracy: {train_accuracy:.2f}%\")\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    with torch.no_grad():\n",
    "        for images, targets in val_loader:\n",
    "            images, targets = images.to(device), targets.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_val += (predicted == targets).sum().item()\n",
    "            total_val += targets.size(0)\n",
    "    \n",
    "    val_accuracy = correct_val / total_val * 100\n",
    "    print(f\"Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "# # 모델 저장\n",
    "# torch.save(model.state_dict(), \"resnet50_skin_model.pth\")\n",
    "# print(\"모델이 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Dev\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Dev\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 2.0393, Train Accuracy: 27.55%\n",
      "Validation Accuracy: 47.09%\n",
      "Epoch 2/10, Loss: 1.6989, Train Accuracy: 26.38%\n",
      "Validation Accuracy: 29.65%\n",
      "Epoch 3/10, Loss: 1.6780, Train Accuracy: 27.99%\n",
      "Validation Accuracy: 4.65%\n",
      "Epoch 4/10, Loss: 1.5915, Train Accuracy: 31.34%\n",
      "Validation Accuracy: 22.67%\n",
      "Epoch 5/10, Loss: 1.4354, Train Accuracy: 26.82%\n",
      "Validation Accuracy: 36.63%\n",
      "Epoch 6/10, Loss: 1.4561, Train Accuracy: 34.69%\n",
      "Validation Accuracy: 12.79%\n",
      "Epoch 7/10, Loss: 1.2424, Train Accuracy: 38.78%\n",
      "Validation Accuracy: 15.12%\n",
      "Epoch 8/10, Loss: 1.2564, Train Accuracy: 40.09%\n",
      "Validation Accuracy: 28.49%\n",
      "Epoch 9/10, Loss: 1.3792, Train Accuracy: 38.78%\n",
      "Validation Accuracy: 41.28%\n",
      "Epoch 10/10, Loss: 1.2370, Train Accuracy: 40.23%\n",
      "Validation Accuracy: 22.67%\n",
      "모델이 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "\n",
    "# Dataset 클래스 정의\n",
    "class SkinDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.images = data[\"Images\"]  # Images: numpy.ndarray 형태로 저장된 이미지들\n",
    "        self.metadata = data[\"Metadata\"]  # Metadata: JSON 메타데이터\n",
    "        self.transform = transform\n",
    "        self.keys = list(self.metadata.keys())  # 데이터 키 리스트\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.keys)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        key = self.keys[idx]\n",
    "        image_data = self.images[key]  # numpy.ndarray 이미지 데이터\n",
    "        metadata = self.metadata[key]  # 메타데이터\n",
    "        \n",
    "        # numpy.ndarray 이미지를 PIL 이미지로 변환\n",
    "        image = Image.fromarray(image_data)\n",
    "        \n",
    "        # 타겟 레이블 (forehead_pigmentation)\n",
    "        target = metadata[\"annotations\"][\"forehead_pigmentation\"]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, target\n",
    "\n",
    "# 이미지 전처리\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # ResNet50 입력 크기에 맞춤\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # ResNet50 사전 학습 기준\n",
    "])\n",
    "\n",
    "# Dataset 및 Train/Validation Split\n",
    "dataset = SkinDataset(test_data_sets, transform=transform)  # test_data_sets는 이미 로드된 상태로 사용\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# 클래스별 데이터 분포 계산\n",
    "targets = [metadata[\"annotations\"][\"forehead_pigmentation\"] for metadata in test_data_sets[\"Metadata\"].values()]\n",
    "target_distribution = Counter(targets)\n",
    "\n",
    "# 클래스 가중치 계산 (전체 샘플 수 / 클래스별 샘플 수)\n",
    "total_samples = len(targets)\n",
    "class_weights = [total_samples / target_distribution[c] for c in range(6)]\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "\n",
    "# ResNet50 모델 로드 및 수정\n",
    "model = models.resnet50(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, 6)  # 출력 클래스 수를 6으로 수정 (0~5)\n",
    "\n",
    "# Weighted Loss 설정\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)  # 클래스 가중치 반영\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # 학습률 0.001\n",
    "\n",
    "# GPU/CPU 장치 설정\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# 학습 및 검증 루프\n",
    "num_epochs = 10  # 에포크 수\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    \n",
    "    for images, targets in train_loader:\n",
    "        images, targets = images.to(device), targets.to(device)\n",
    "        \n",
    "        # 옵티마이저 초기화\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 모델 출력 및 손실 계산\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # 역전파 및 가중치 업데이트\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_train += (predicted == targets).sum().item()\n",
    "        total_train += targets.size(0)\n",
    "    \n",
    "    train_accuracy = correct_train / total_train * 100\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader):.4f}, Train Accuracy: {train_accuracy:.2f}%\")\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    with torch.no_grad():\n",
    "        for images, targets in val_loader:\n",
    "            images, targets = images.to(device), targets.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_val += (predicted == targets).sum().item()\n",
    "            total_val += targets.size(0)\n",
    "    \n",
    "    val_accuracy = correct_val / total_val * 100\n",
    "    print(f\"Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "# # 모델 저장\n",
    "# torch.save(model.state_dict(), \"resnet50_skin_model_with_weights.pth\")\n",
    "# print(\"모델이 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 2.0615, Train Accuracy: 24.49%\n",
      "Validation Accuracy: 4.07%\n",
      "Epoch 2/20, Loss: 1.5989, Train Accuracy: 30.47%\n",
      "Validation Accuracy: 10.47%\n",
      "Epoch 3/20, Loss: 1.3892, Train Accuracy: 34.40%\n",
      "Validation Accuracy: 11.63%\n",
      "Epoch 4/20, Loss: 1.5051, Train Accuracy: 31.05%\n",
      "Validation Accuracy: 34.30%\n",
      "Epoch 5/20, Loss: 1.2860, Train Accuracy: 31.92%\n",
      "Validation Accuracy: 33.72%\n",
      "Epoch 6/20, Loss: 1.3218, Train Accuracy: 38.92%\n",
      "Validation Accuracy: 34.30%\n",
      "Epoch 7/20, Loss: 1.4339, Train Accuracy: 34.55%\n",
      "Validation Accuracy: 31.40%\n",
      "Epoch 8/20, Loss: 1.2507, Train Accuracy: 36.59%\n",
      "Validation Accuracy: 31.98%\n",
      "Epoch 9/20, Loss: 1.2162, Train Accuracy: 37.32%\n",
      "Validation Accuracy: 33.72%\n",
      "Epoch 10/20, Loss: 1.2626, Train Accuracy: 39.80%\n",
      "Validation Accuracy: 33.72%\n",
      "Epoch 11/20, Loss: 1.1960, Train Accuracy: 40.82%\n",
      "Validation Accuracy: 34.88%\n",
      "Epoch 12/20, Loss: 1.2492, Train Accuracy: 38.92%\n",
      "Validation Accuracy: 34.88%\n",
      "Epoch 13/20, Loss: 1.3346, Train Accuracy: 39.36%\n",
      "Validation Accuracy: 34.30%\n",
      "Epoch 14/20, Loss: 1.3471, Train Accuracy: 39.80%\n",
      "Validation Accuracy: 34.88%\n",
      "Epoch 15/20, Loss: 1.1294, Train Accuracy: 39.80%\n",
      "Validation Accuracy: 35.47%\n",
      "Epoch 16/20, Loss: 1.2098, Train Accuracy: 40.96%\n",
      "Validation Accuracy: 34.30%\n",
      "Epoch 17/20, Loss: 1.2395, Train Accuracy: 39.80%\n",
      "Validation Accuracy: 33.14%\n",
      "Epoch 18/20, Loss: 1.2302, Train Accuracy: 39.50%\n",
      "Validation Accuracy: 36.05%\n",
      "Epoch 19/20, Loss: 1.3069, Train Accuracy: 41.11%\n",
      "Validation Accuracy: 35.47%\n",
      "Epoch 20/20, Loss: 1.0795, Train Accuracy: 40.82%\n",
      "Validation Accuracy: 35.47%\n",
      "학습 완료.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "from torchvision.transforms import functional as TF\n",
    "\n",
    "# Dataset 클래스 정의 (증강 포함)\n",
    "class SkinDataset(Dataset):\n",
    "    def __init__(self, data, transform=None, augment=False):\n",
    "        self.data = data\n",
    "        self.images = data[\"Images\"]\n",
    "        self.metadata = data[\"Metadata\"]\n",
    "        self.transform = transform\n",
    "        self.augment = augment\n",
    "        self.keys = list(self.metadata.keys())  # 데이터 키 리스트\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.keys)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        key = self.keys[idx]\n",
    "        image_data = self.images[key]  # numpy.ndarray 이미지 데이터\n",
    "        metadata = self.metadata[key]  # 메타데이터\n",
    "        \n",
    "        # numpy.ndarray 이미지를 PIL 이미지로 변환\n",
    "        image = Image.fromarray(image_data)\n",
    "        \n",
    "        # 타겟 레이블 (forehead_pigmentation)\n",
    "        target = metadata[\"annotations\"][\"forehead_pigmentation\"]\n",
    "        \n",
    "        # 증강 적용 (소수 클래스만)\n",
    "        if self.augment and target in [4, 5]:\n",
    "            if torch.rand(1).item() > 0.5:\n",
    "                image = TF.hflip(image)\n",
    "            if torch.rand(1).item() > 0.5:\n",
    "                image = TF.rotate(image, angle=torch.randint(-30, 30, (1,)).item())\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, target\n",
    "\n",
    "# 이미지 전처리\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Dataset 및 Train/Validation Split\n",
    "dataset = SkinDataset(test_data_sets, transform=transform, augment=True)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# 클래스 가중치 계산\n",
    "targets = [metadata[\"annotations\"][\"forehead_pigmentation\"] for metadata in test_data_sets[\"Metadata\"].values()]\n",
    "target_distribution = Counter(targets)\n",
    "total_samples = len(targets)\n",
    "class_weights = [total_samples / target_distribution[c] for c in range(6)]\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "\n",
    "# ResNet50 모델 로드 및 수정\n",
    "model = models.resnet50(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, 6)\n",
    "\n",
    "# Weighted Loss, Optimizer 및 Learning Rate Scheduler\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "# GPU/CPU 장치 설정\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# 학습 및 검증 루프\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    \n",
    "    for images, targets in train_loader:\n",
    "        images, targets = images.to(device), targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_train += (predicted == targets).sum().item()\n",
    "        total_train += targets.size(0)\n",
    "    \n",
    "    train_accuracy = correct_train / total_train * 100\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader):.4f}, Train Accuracy: {train_accuracy:.2f}%\")\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    with torch.no_grad():\n",
    "        for images, targets in val_loader:\n",
    "            images, targets = images.to(device), targets.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_val += (predicted == targets).sum().item()\n",
    "            total_val += targets.size(0)\n",
    "    \n",
    "    val_accuracy = correct_val / total_val * 100\n",
    "    print(f\"Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "    \n",
    "    # 학습률 조정\n",
    "    scheduler.step()\n",
    "\n",
    "print(\"학습 완료.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Dev\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to C:\\Users\\oos04/.cache\\torch\\hub\\checkpoints\\efficientnet_b0_rwightman-7f5810bc.pth\n",
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 1.7835, Train Accuracy: 30.32%\n",
      "Validation Accuracy: 27.91%\n",
      "Epoch 2/20, Loss: 1.5319, Train Accuracy: 31.63%\n",
      "Validation Accuracy: 33.14%\n",
      "Epoch 3/20, Loss: 1.4371, Train Accuracy: 36.30%\n",
      "Validation Accuracy: 38.95%\n",
      "Epoch 4/20, Loss: 1.4092, Train Accuracy: 39.65%\n",
      "Validation Accuracy: 38.37%\n",
      "Epoch 5/20, Loss: 1.3596, Train Accuracy: 41.69%\n",
      "Validation Accuracy: 37.79%\n",
      "Epoch 6/20, Loss: 1.2474, Train Accuracy: 43.88%\n",
      "Validation Accuracy: 43.02%\n",
      "Epoch 7/20, Loss: 1.1257, Train Accuracy: 45.63%\n",
      "Validation Accuracy: 44.19%\n",
      "Epoch 8/20, Loss: 1.1634, Train Accuracy: 47.81%\n",
      "Validation Accuracy: 38.37%\n",
      "Epoch 9/20, Loss: 1.1544, Train Accuracy: 45.34%\n",
      "Validation Accuracy: 44.19%\n",
      "Epoch 10/20, Loss: 1.1294, Train Accuracy: 49.56%\n",
      "Validation Accuracy: 38.95%\n",
      "Epoch 11/20, Loss: 1.1406, Train Accuracy: 47.08%\n",
      "Validation Accuracy: 44.77%\n",
      "Epoch 12/20, Loss: 1.1281, Train Accuracy: 49.56%\n",
      "Validation Accuracy: 40.70%\n",
      "Epoch 13/20, Loss: 1.1085, Train Accuracy: 47.81%\n",
      "Validation Accuracy: 45.93%\n",
      "Epoch 14/20, Loss: 1.1769, Train Accuracy: 45.04%\n",
      "Validation Accuracy: 45.93%\n",
      "Epoch 15/20, Loss: 1.1301, Train Accuracy: 46.50%\n",
      "Validation Accuracy: 40.70%\n",
      "Epoch 16/20, Loss: 1.1158, Train Accuracy: 47.52%\n",
      "Validation Accuracy: 45.35%\n",
      "Epoch 17/20, Loss: 1.1888, Train Accuracy: 47.38%\n",
      "Validation Accuracy: 41.28%\n",
      "Epoch 18/20, Loss: 1.1691, Train Accuracy: 45.77%\n",
      "Validation Accuracy: 42.44%\n",
      "Epoch 19/20, Loss: 1.1604, Train Accuracy: 50.87%\n",
      "Validation Accuracy: 43.60%\n",
      "Epoch 20/20, Loss: 1.1571, Train Accuracy: 45.34%\n",
      "Validation Accuracy: 50.00%\n",
      "학습 완료.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "from torchvision.models import efficientnet_b0\n",
    "from torchvision.transforms import functional as TF\n",
    "\n",
    "# Dataset 클래스 정의 (증강 포함)\n",
    "class SkinDataset(Dataset):\n",
    "    def __init__(self, data, transform=None, augment=False):\n",
    "        self.data = data\n",
    "        self.images = data[\"Images\"]\n",
    "        self.metadata = data[\"Metadata\"]\n",
    "        self.transform = transform\n",
    "        self.augment = augment\n",
    "        self.keys = list(self.metadata.keys())  # 데이터 키 리스트\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.keys)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        key = self.keys[idx]\n",
    "        image_data = self.images[key]  # numpy.ndarray 이미지 데이터\n",
    "        metadata = self.metadata[key]  # 메타데이터\n",
    "        \n",
    "        # numpy.ndarray 이미지를 PIL 이미지로 변환\n",
    "        image = Image.fromarray(image_data)\n",
    "        \n",
    "        # 타겟 레이블 (forehead_pigmentation)\n",
    "        target = metadata[\"annotations\"][\"forehead_pigmentation\"]\n",
    "        \n",
    "        # 증강 적용 (전체 클래스)\n",
    "        if self.augment:\n",
    "            if torch.rand(1).item() > 0.5:\n",
    "                image = TF.hflip(image)\n",
    "            if torch.rand(1).item() > 0.5:\n",
    "                image = TF.adjust_brightness(image, brightness_factor=torch.rand(1).item() + 0.5)\n",
    "            if torch.rand(1).item() > 0.5:\n",
    "                image = TF.rotate(image, angle=torch.randint(-30, 30, (1,)).item())\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, target\n",
    "\n",
    "# 이미지 전처리\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Dataset 및 Train/Validation Split\n",
    "dataset = SkinDataset(test_data_sets, transform=transform, augment=True)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# 클래스 가중치 계산\n",
    "targets = [metadata[\"annotations\"][\"forehead_pigmentation\"] for metadata in test_data_sets[\"Metadata\"].values()]\n",
    "target_distribution = Counter(targets)\n",
    "total_samples = len(targets)\n",
    "class_weights = [total_samples / target_distribution[c] for c in range(6)]\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "\n",
    "# EfficientNet 모델 로드 및 수정\n",
    "model = efficientnet_b0(pretrained=True)\n",
    "model.classifier[1] = nn.Linear(model.classifier[1].in_features, 6)  # 출력 클래스 변경\n",
    "\n",
    "# Weighted Loss, Optimizer 및 Learning Rate Scheduler\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "# GPU/CPU 장치 설정\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# 학습 및 검증 루프\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    \n",
    "    for images, targets in train_loader:\n",
    "        images, targets = images.to(device), targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_train += (predicted == targets).sum().item()\n",
    "        total_train += targets.size(0)\n",
    "    \n",
    "    train_accuracy = correct_train / total_train * 100\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader):.4f}, Train Accuracy: {train_accuracy:.2f}%\")\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    with torch.no_grad():\n",
    "        for images, targets in val_loader:\n",
    "            images, targets = images.to(device), targets.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_val += (predicted == targets).sum().item()\n",
    "            total_val += targets.size(0)\n",
    "    \n",
    "    val_accuracy = correct_val / total_val * 100\n",
    "    print(f\"Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "    \n",
    "    # 학습률 조정\n",
    "    scheduler.step()\n",
    "\n",
    "print(\"학습 완료.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 1.8859, Train Accuracy: 23.91%\n",
      "Validation Accuracy: 12.79%\n",
      "Epoch 2/20, Loss: 1.7446, Train Accuracy: 26.53%\n",
      "Validation Accuracy: 23.84%\n",
      "Epoch 3/20, Loss: 1.6674, Train Accuracy: 24.78%\n",
      "Validation Accuracy: 29.07%\n",
      "Epoch 4/20, Loss: 1.6601, Train Accuracy: 27.99%\n",
      "Validation Accuracy: 28.49%\n",
      "Epoch 5/20, Loss: 1.6826, Train Accuracy: 36.73%\n",
      "Validation Accuracy: 31.40%\n",
      "Epoch 6/20, Loss: 1.5861, Train Accuracy: 34.84%\n",
      "Validation Accuracy: 27.91%\n",
      "Epoch 7/20, Loss: 1.5645, Train Accuracy: 35.86%\n",
      "Validation Accuracy: 25.58%\n",
      "Epoch 8/20, Loss: 1.5950, Train Accuracy: 31.20%\n",
      "Validation Accuracy: 31.40%\n",
      "Epoch 9/20, Loss: 1.5616, Train Accuracy: 33.67%\n",
      "Validation Accuracy: 30.81%\n",
      "Epoch 10/20, Loss: 1.5431, Train Accuracy: 32.36%\n",
      "Validation Accuracy: 34.88%\n",
      "Epoch 11/20, Loss: 1.5145, Train Accuracy: 32.51%\n",
      "Validation Accuracy: 30.81%\n",
      "Epoch 12/20, Loss: 1.5493, Train Accuracy: 36.59%\n",
      "Validation Accuracy: 30.23%\n",
      "Epoch 13/20, Loss: 1.4932, Train Accuracy: 38.19%\n",
      "Validation Accuracy: 29.65%\n",
      "Epoch 14/20, Loss: 1.5553, Train Accuracy: 36.15%\n",
      "Validation Accuracy: 29.65%\n",
      "Epoch 15/20, Loss: 1.5711, Train Accuracy: 33.67%\n",
      "Validation Accuracy: 30.81%\n",
      "Early stopping triggered.\n",
      "학습 완료.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torchvision.models import resnet50\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "from torchvision.transforms import functional as TF\n",
    "\n",
    "# ResNet50 기반 모델 정의\n",
    "class CustomResNet50(nn.Module):\n",
    "    def __init__(self, num_classes=6):\n",
    "        super(CustomResNet50, self).__init__()\n",
    "        # 사전 학습된 ResNet50 모델 로드\n",
    "        self.resnet = resnet50(pretrained=True)\n",
    "        \n",
    "        # 마지막 Fully Connected 레이어 교체\n",
    "        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "# Early Stopping 클래스 정의\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, delta=0):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.counter = 0\n",
    "\n",
    "    def __call__(self, val_accuracy):\n",
    "        score = val_accuracy\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.counter = 0\n",
    "\n",
    "# Dataset 클래스 정의 (증강 포함)\n",
    "class SkinDataset(Dataset):\n",
    "    def __init__(self, data, transform=None, augment=False):\n",
    "        self.data = data\n",
    "        self.images = data[\"Images\"]\n",
    "        self.metadata = data[\"Metadata\"]\n",
    "        self.transform = transform\n",
    "        self.augment = augment\n",
    "        self.keys = list(self.metadata.keys())  # 데이터 키 리스트\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.keys)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        key = self.keys[idx]\n",
    "        image_data = self.images[key]  # numpy.ndarray 이미지 데이터\n",
    "        metadata = self.metadata[key]  # 메타데이터\n",
    "        \n",
    "        # numpy.ndarray 이미지를 PIL 이미지로 변환\n",
    "        image = Image.fromarray(image_data)\n",
    "        \n",
    "        # 타겟 레이블 (forehead_pigmentation)\n",
    "        target = metadata[\"annotations\"][\"forehead_pigmentation\"]\n",
    "        \n",
    "        # 증강 적용 (전체 클래스)\n",
    "        if self.augment:\n",
    "            if torch.rand(1).item() > 0.5:\n",
    "                image = TF.hflip(image)\n",
    "            if torch.rand(1).item() > 0.5:\n",
    "                image = TF.adjust_brightness(image, brightness_factor=torch.rand(1).item() + 0.5)\n",
    "            if torch.rand(1).item() > 0.5:\n",
    "                image = TF.rotate(image, angle=torch.randint(-30, 30, (1,)).item())\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, target\n",
    "\n",
    "# 이미지 전처리\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Dataset 및 Train/Validation Split\n",
    "dataset = SkinDataset(test_data_sets, transform=transform, augment=True)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# 클래스 가중치 계산\n",
    "targets = [metadata[\"annotations\"][\"forehead_pigmentation\"] for metadata in test_data_sets[\"Metadata\"].values()]\n",
    "target_distribution = Counter(targets)\n",
    "total_samples = len(targets)\n",
    "class_weights = [total_samples / target_distribution[c] for c in range(6)]\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "\n",
    "# 모델 생성\n",
    "num_classes = 6  # 출력 클래스 수\n",
    "model = CustomResNet50(num_classes=num_classes)\n",
    "\n",
    "# Weighted Loss, Optimizer 및 Learning Rate Scheduler\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "# GPU/CPU 장치 설정\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# 학습 및 검증 루프\n",
    "num_epochs = 20\n",
    "early_stopping = EarlyStopping(patience=5)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    \n",
    "    for images, targets in train_loader:\n",
    "        images, targets = images.to(device), targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_train += (predicted == targets).sum().item()\n",
    "        total_train += targets.size(0)\n",
    "    \n",
    "    train_accuracy = correct_train / total_train * 100\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader):.4f}, Train Accuracy: {train_accuracy:.2f}%\")\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    with torch.no_grad():\n",
    "        for images, targets in val_loader:\n",
    "            images, targets = images.to(device), targets.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_val += (predicted == targets).sum().item()\n",
    "            total_val += targets.size(0)\n",
    "    \n",
    "    val_accuracy = correct_val / total_val * 100\n",
    "    print(f\"Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "    \n",
    "    # 학습률 조정\n",
    "    scheduler.step()\n",
    "\n",
    "    # Early Stopping 체크\n",
    "    early_stopping(val_accuracy)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break\n",
    "\n",
    "print(\"학습 완료.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 1.2685, Train Accuracy: 0.6254, Validation Accuracy: 0.4244\n",
      "Epoch 2/10, Loss: 0.6120, Train Accuracy: 0.9242, Validation Accuracy: 0.4593\n",
      "Epoch 3/10, Loss: 0.2055, Train Accuracy: 0.9636, Validation Accuracy: 0.4709\n",
      "Epoch 4/10, Loss: 0.1053, Train Accuracy: 0.9883, Validation Accuracy: 0.4942\n",
      "Epoch 5/10, Loss: 0.0979, Train Accuracy: 0.9840, Validation Accuracy: 0.5233\n",
      "Epoch 6/10, Loss: 0.1211, Train Accuracy: 0.9227, Validation Accuracy: 0.4593\n",
      "Epoch 7/10, Loss: 0.1519, Train Accuracy: 0.9752, Validation Accuracy: 0.5349\n",
      "Epoch 8/10, Loss: 0.0995, Train Accuracy: 0.9402, Validation Accuracy: 0.5000\n",
      "Epoch 9/10, Loss: 0.0819, Train Accuracy: 0.9752, Validation Accuracy: 0.4709\n",
      "Epoch 10/10, Loss: 0.1018, Train Accuracy: 0.9883, Validation Accuracy: 0.4884\n",
      "모델 학습 완료!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# 데이터셋 클래스를 정의합니다.\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_dict, transform=None):\n",
    "        self.images = list(data_dict[\"Images\"].values())\n",
    "        self.targets = [meta[\"annotations\"][\"forehead_pigmentation\"] for meta in data_dict[\"Metadata\"].values()]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        target = self.targets[idx]\n",
    "\n",
    "        # numpy.ndarray 이미지를 PIL 이미지로 변환\n",
    "        if isinstance(image, np.ndarray):\n",
    "            image = Image.fromarray(image)\n",
    "\n",
    "        # Transform 적용\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, target\n",
    "\n",
    "# 데이터 변환(transform)을 정의합니다.\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # ResNet 입력 크기에 맞춤\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 데이터셋 생성\n",
    "dataset = CustomDataset(test_data_sets, transform=transform)\n",
    "\n",
    "# 학습 데이터와 검증 데이터로 분리 (8:2 비율)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# 데이터 로더 생성\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# 사전학습된 ResNet50 모델 불러오기\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "# 출력 클래스를 데이터셋에 맞게 조정\n",
    "num_classes = len(set(meta[\"annotations\"][\"forehead_pigmentation\"] for meta in test_data_sets[\"Metadata\"].values()))  # 타겟의 고유 클래스 수 계산\n",
    "model.fc = nn.Linear(2048, num_classes)  # Fully Connected Layer 수정\n",
    "\n",
    "# 모델 학습 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  # 손실 함수\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)  # 옵티마이저\n",
    "\n",
    "# 정확도 계산 함수\n",
    "def calculate_accuracy(loader, model):\n",
    "    model.eval()  # 평가 모드\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, targets in loader:\n",
    "            images, targets = images.to(device), targets.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "    return correct / total\n",
    "\n",
    "# 학습 루프 정의\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # 학습 모드\n",
    "    running_loss = 0.0\n",
    "    for images, targets in train_loader:\n",
    "        images, targets = images.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # 학습 및 검증 정확도 계산\n",
    "    train_accuracy = calculate_accuracy(train_loader, model)\n",
    "    val_accuracy = calculate_accuracy(val_loader, model)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss / len(train_loader):.4f}, \"\n",
    "          f\"Train Accuracy: {train_accuracy:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "print(\"모델 학습 완료!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 1.3090, Train Accuracy: 0.6414, Validation Accuracy: 0.4651\n",
      "Epoch 2/10, Loss: 0.6475, Train Accuracy: 0.8761, Validation Accuracy: 0.5058\n",
      "Epoch 3/10, Loss: 0.2586, Train Accuracy: 0.9344, Validation Accuracy: 0.4593\n",
      "Epoch 4/10, Loss: 0.1300, Train Accuracy: 0.9942, Validation Accuracy: 0.4360\n",
      "Epoch 5/10, Loss: 0.0893, Train Accuracy: 0.9913, Validation Accuracy: 0.4826\n",
      "Epoch 6/10, Loss: 0.1279, Train Accuracy: 0.9679, Validation Accuracy: 0.4709\n",
      "Epoch 7/10, Loss: 0.1304, Train Accuracy: 0.8950, Validation Accuracy: 0.4709\n",
      "Epoch 8/10, Loss: 0.1578, Train Accuracy: 0.9927, Validation Accuracy: 0.5058\n",
      "Epoch 9/10, Loss: 0.1785, Train Accuracy: 0.9548, Validation Accuracy: 0.4651\n",
      "Epoch 10/10, Loss: 0.1449, Train Accuracy: 0.9840, Validation Accuracy: 0.5174\n",
      "모델 학습 완료!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# 데이터셋 클래스를 정의합니다.\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_dict, transform=None, augment=None):\n",
    "        self.images = list(data_dict[\"Images\"].values())\n",
    "        self.targets = [meta[\"annotations\"][\"forehead_pigmentation\"] for meta in data_dict[\"Metadata\"].values()]\n",
    "        self.transform = transform\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        target = self.targets[idx]\n",
    "\n",
    "        # numpy.ndarray 이미지를 PIL 이미지로 변환\n",
    "        if isinstance(image, np.ndarray):\n",
    "            image = Image.fromarray(image)\n",
    "\n",
    "        # 증강 적용 (소수 클래스만)\n",
    "        if self.augment and target in [4, 5]:\n",
    "            if np.random.rand() > 0.5:\n",
    "                image = transforms.functional.hflip(image)\n",
    "            if np.random.rand() > 0.5:\n",
    "                image = transforms.functional.adjust_brightness(image, brightness_factor=1.2)\n",
    "            if np.random.rand() > 0.5:\n",
    "                image = transforms.functional.adjust_contrast(image, contrast_factor=1.2)\n",
    "            if np.random.rand() > 0.5:\n",
    "                image = transforms.functional.rotate(image, angle=np.random.uniform(-30, 30))\n",
    "\n",
    "        # Transform 적용\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, target\n",
    "\n",
    "# 데이터 변환(transform)을 정의합니다.\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # ResNet 입력 크기에 맞춤\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 데이터셋 생성\n",
    "dataset = CustomDataset(test_data_sets, transform=transform, augment=True)\n",
    "\n",
    "# 학습 데이터와 검증 데이터로 분리 (8:2 비율)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# 데이터 로더 생성\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# 사전학습된 ResNet50 모델 불러오기\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "# 출력 클래스를 데이터셋에 맞게 조정\n",
    "num_classes = len(set(meta[\"annotations\"][\"forehead_pigmentation\"] for meta in test_data_sets[\"Metadata\"].values()))  # 타겟의 고유 클래스 수 계산\n",
    "model.fc = nn.Linear(2048, num_classes)  # Fully Connected Layer 수정\n",
    "\n",
    "# 모델 학습 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  # 손실 함수\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)  # 옵티마이저\n",
    "\n",
    "# 정확도 계산 함수\n",
    "def calculate_accuracy(loader, model):\n",
    "    model.eval()  # 평가 모드\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, targets in loader:\n",
    "            images, targets = images.to(device), targets.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "    return correct / total\n",
    "\n",
    "# 학습 루프 정의\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # 학습 모드\n",
    "    running_loss = 0.0\n",
    "    for images, targets in train_loader:\n",
    "        images, targets = images.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # 학습 및 검증 정확도 계산\n",
    "    train_accuracy = calculate_accuracy(train_loader, model)\n",
    "    val_accuracy = calculate_accuracy(val_loader, model)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss / len(train_loader):.4f}, \"\n",
    "          f\"Train Accuracy: {train_accuracy:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "print(\"모델 학습 완료!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 1.3148, Train Accuracy: 0.6224, Validation Accuracy: 0.4942\n",
      "Epoch 2/10, Loss: 0.7529, Train Accuracy: 0.8251, Validation Accuracy: 0.5407\n",
      "Epoch 3/10, Loss: 0.3854, Train Accuracy: 0.9679, Validation Accuracy: 0.5291\n",
      "Epoch 4/10, Loss: 0.2044, Train Accuracy: 0.9942, Validation Accuracy: 0.5988\n",
      "Epoch 5/10, Loss: 0.0976, Train Accuracy: 0.9810, Validation Accuracy: 0.4535\n",
      "Epoch 6/10, Loss: 0.0769, Train Accuracy: 0.9942, Validation Accuracy: 0.5349\n",
      "Epoch 7/10, Loss: 0.0602, Train Accuracy: 1.0000, Validation Accuracy: 0.5523\n",
      "Epoch 8/10, Loss: 0.0467, Train Accuracy: 0.9971, Validation Accuracy: 0.5233\n",
      "Epoch 9/10, Loss: 0.0272, Train Accuracy: 0.9985, Validation Accuracy: 0.5349\n",
      "Early stopping triggered.\n",
      "모델 학습 완료!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# 데이터셋 클래스를 정의합니다.\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_dict, transform=None, augment=None):\n",
    "        self.images = list(data_dict[\"Images\"].values())\n",
    "        self.targets = [meta[\"annotations\"][\"forehead_pigmentation\"] for meta in data_dict[\"Metadata\"].values()]\n",
    "        self.transform = transform\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        target = self.targets[idx]\n",
    "\n",
    "        # numpy.ndarray 이미지를 PIL 이미지로 변환\n",
    "        if isinstance(image, np.ndarray):\n",
    "            image = Image.fromarray(image)\n",
    "\n",
    "        # 증강 적용 (소수 클래스만)\n",
    "        if self.augment and target in [4, 5]:\n",
    "            if np.random.rand() > 0.5:\n",
    "                image = transforms.functional.hflip(image)\n",
    "            if np.random.rand() > 0.5:\n",
    "                image = transforms.functional.adjust_brightness(image, brightness_factor=1.2)\n",
    "            if np.random.rand() > 0.5:\n",
    "                image = transforms.functional.adjust_contrast(image, contrast_factor=1.2)\n",
    "            if np.random.rand() > 0.5:\n",
    "                image = transforms.functional.rotate(image, angle=np.random.uniform(-30, 30))\n",
    "\n",
    "        # Transform 적용\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, target\n",
    "\n",
    "# 데이터 변환(transform)을 정의합니다.\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # ResNet 입력 크기에 맞춤\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 데이터셋 생성\n",
    "dataset = CustomDataset(test_data_sets, transform=transform, augment=True)\n",
    "\n",
    "# 학습 데이터와 검증 데이터로 분리 (8:2 비율)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# 데이터 로더 생성\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# ResNet50 기반 모델 정의\n",
    "class ModifiedResNet50(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ModifiedResNet50, self).__init__()\n",
    "        self.resnet = models.resnet50(pretrained=True)\n",
    "        self.resnet.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),  # Dropout 추가\n",
    "            nn.Linear(2048, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "# 출력 클래스를 데이터셋에 맞게 조정\n",
    "num_classes = len(set(meta[\"annotations\"][\"forehead_pigmentation\"] for meta in test_data_sets[\"Metadata\"].values()))  # 타겟의 고유 클래스 수 계산\n",
    "model = ModifiedResNet50(num_classes=num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "# 모델 학습 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "criterion = nn.CrossEntropyLoss()  # 손실 함수\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)  # 옵티마이저\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "# Early Stopping 클래스 정의\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.best_accuracy = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_accuracy):\n",
    "        if val_accuracy > self.best_accuracy:\n",
    "            self.best_accuracy = val_accuracy\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "# Early Stopping 초기화\n",
    "early_stopping = EarlyStopping(patience=5)\n",
    "\n",
    "# 정확도 계산 함수\n",
    "def calculate_accuracy(loader, model):\n",
    "    model.eval()  # 평가 모드\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, targets in loader:\n",
    "            images, targets = images.to(device), targets.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "    return correct / total\n",
    "\n",
    "# 학습 루프 정의\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # 학습 모드\n",
    "    running_loss = 0.0\n",
    "    for images, targets in train_loader:\n",
    "        images, targets = images.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # 학습 및 검증 정확도 계산\n",
    "    train_accuracy = calculate_accuracy(train_loader, model)\n",
    "    val_accuracy = calculate_accuracy(val_loader, model)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss / len(train_loader):.4f}, \"\n",
    "          f\"Train Accuracy: {train_accuracy:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "    # Learning Rate Scheduler 스텝\n",
    "    scheduler.step()\n",
    "\n",
    "    # Early Stopping 체크\n",
    "    early_stopping(val_accuracy)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break\n",
    "\n",
    "print(\"모델 학습 완료!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 1.6680, Train Accuracy: 0.5058, Validation Accuracy: 0.4651\n",
      "Epoch 2/20, Loss: 1.2231, Train Accuracy: 0.7012, Validation Accuracy: 0.4942\n",
      "Epoch 3/20, Loss: 0.8784, Train Accuracy: 0.8571, Validation Accuracy: 0.5523\n",
      "Epoch 4/20, Loss: 0.7907, Train Accuracy: 0.8076, Validation Accuracy: 0.5000\n",
      "Epoch 5/20, Loss: 0.7268, Train Accuracy: 0.9388, Validation Accuracy: 0.5233\n",
      "Epoch 6/20, Loss: 0.4286, Train Accuracy: 0.9694, Validation Accuracy: 0.5349\n",
      "Epoch 7/20, Loss: 0.3272, Train Accuracy: 0.9825, Validation Accuracy: 0.5698\n",
      "Epoch 8/20, Loss: 0.2619, Train Accuracy: 0.9869, Validation Accuracy: 0.5640\n",
      "Epoch 9/20, Loss: 0.2285, Train Accuracy: 0.9898, Validation Accuracy: 0.5407\n",
      "Epoch 10/20, Loss: 0.2618, Train Accuracy: 0.9927, Validation Accuracy: 0.5523\n",
      "Epoch 11/20, Loss: 0.2209, Train Accuracy: 0.9942, Validation Accuracy: 0.5349\n",
      "Epoch 12/20, Loss: 0.2581, Train Accuracy: 0.9898, Validation Accuracy: 0.5349\n",
      "Early stopping triggered.\n",
      "모델 학습 완료!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# 데이터셋 클래스를 정의합니다.\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_dict, transform=None, augment=None):\n",
    "        self.images = list(data_dict[\"Images\"].values())\n",
    "        self.targets = [meta[\"annotations\"][\"forehead_pigmentation\"] for meta in data_dict[\"Metadata\"].values()]\n",
    "        self.transform = transform\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        target = self.targets[idx]\n",
    "\n",
    "        # numpy.ndarray 이미지를 PIL 이미지로 변환\n",
    "        if isinstance(image, np.ndarray):\n",
    "            image = Image.fromarray(image)\n",
    "\n",
    "        # 증강 적용 (소수 클래스만)\n",
    "        if self.augment and target in [4, 5]:\n",
    "            if np.random.rand() > 0.5:\n",
    "                image = transforms.functional.hflip(image)\n",
    "            if np.random.rand() > 0.5:\n",
    "                image = transforms.functional.adjust_brightness(image, brightness_factor=1.2)\n",
    "            if np.random.rand() > 0.5:\n",
    "                image = transforms.functional.adjust_contrast(image, contrast_factor=1.2)\n",
    "            if np.random.rand() > 0.5:\n",
    "                image = transforms.functional.rotate(image, angle=np.random.uniform(-30, 30))\n",
    "\n",
    "        # Transform 적용\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, target\n",
    "\n",
    "# 데이터 변환(transform)을 정의합니다.\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # ResNet 입력 크기에 맞춤\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 데이터셋 생성\n",
    "dataset = CustomDataset(test_data_sets, transform=transform, augment=True)\n",
    "\n",
    "# 학습 데이터와 검증 데이터로 분리 (8:2 비율)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# 데이터 로더 생성\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# ResNet50 기반 모델 정의\n",
    "class ModifiedResNet50(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ModifiedResNet50, self).__init__()\n",
    "        self.resnet = models.resnet50(pretrained=True)\n",
    "        self.resnet.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),  # Dropout 추가\n",
    "            nn.Linear(2048, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "# 출력 클래스를 데이터셋에 맞게 조정\n",
    "num_classes = len(set(meta[\"annotations\"][\"forehead_pigmentation\"] for meta in test_data_sets[\"Metadata\"].values()))  # 타겟의 고유 클래스 수 계산\n",
    "model = ModifiedResNet50(num_classes=num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "# 클래스 가중치 계산 및 CrossEntropyLoss에 적용\n",
    "class_counts = [175, 443, 163, 69, 6, 2]  # 클래스별 샘플 개수\n",
    "class_weights = torch.tensor([1.0 / count for count in class_counts], dtype=torch.float32).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)  # 손실 함수에 클래스 가중치 적용\n",
    "\n",
    "# 모델 학습 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)  # 옵티마이저\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "# Early Stopping 클래스 정의\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.best_accuracy = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_accuracy):\n",
    "        if val_accuracy > self.best_accuracy:\n",
    "            self.best_accuracy = val_accuracy\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "# Early Stopping 초기화\n",
    "early_stopping = EarlyStopping(patience=5)\n",
    "\n",
    "# 정확도 계산 함수\n",
    "def calculate_accuracy(loader, model):\n",
    "    model.eval()  # 평가 모드\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, targets in loader:\n",
    "            images, targets = images.to(device), targets.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "    return correct / total\n",
    "\n",
    "# 학습 루프 정의\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # 학습 모드\n",
    "    running_loss = 0.0\n",
    "    for images, targets in train_loader:\n",
    "        images, targets = images.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # 학습 및 검증 정확도 계산\n",
    "    train_accuracy = calculate_accuracy(train_loader, model)\n",
    "    val_accuracy = calculate_accuracy(val_loader, model)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss / len(train_loader):.4f}, \"\n",
    "          f\"Train Accuracy: {train_accuracy:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "    # Learning Rate Scheduler 스텝\n",
    "    scheduler.step()\n",
    "\n",
    "    # Early Stopping 체크\n",
    "    early_stopping(val_accuracy)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break\n",
    "\n",
    "print(\"모델 학습 완료!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>한등급차이 맞다고 인정</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 1.7560, Train Accuracy: 0.9082, Validation Accuracy: 0.8721\n",
      "Epoch 2/10, Loss: 1.3419, Train Accuracy: 0.9621, Validation Accuracy: 0.9477\n",
      "Epoch 3/10, Loss: 0.9562, Train Accuracy: 0.9650, Validation Accuracy: 0.9186\n",
      "Epoch 4/10, Loss: 0.7141, Train Accuracy: 0.9942, Validation Accuracy: 0.9535\n",
      "Epoch 5/10, Loss: 0.4647, Train Accuracy: 0.9854, Validation Accuracy: 0.9186\n",
      "Epoch 6/10, Loss: 0.3188, Train Accuracy: 0.9956, Validation Accuracy: 0.9477\n",
      "Epoch 7/10, Loss: 0.2542, Train Accuracy: 0.9985, Validation Accuracy: 0.9651\n",
      "Epoch 8/10, Loss: 0.2615, Train Accuracy: 0.9985, Validation Accuracy: 0.9593\n",
      "Epoch 9/10, Loss: 0.2543, Train Accuracy: 0.9985, Validation Accuracy: 0.9535\n",
      "Epoch 10/10, Loss: 0.1947, Train Accuracy: 0.9985, Validation Accuracy: 0.9651\n",
      "모델 학습 완료!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# 데이터셋 클래스를 정의합니다.\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_dict, transform=None, augment=None):\n",
    "        self.images = list(data_dict[\"Images\"].values())\n",
    "        self.targets = [meta[\"annotations\"][\"forehead_pigmentation\"] for meta in data_dict[\"Metadata\"].values()]\n",
    "        self.transform = transform\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        target = self.targets[idx]\n",
    "\n",
    "        # numpy.ndarray 이미지를 PIL 이미지로 변환\n",
    "        if isinstance(image, np.ndarray):\n",
    "            image = Image.fromarray(image)\n",
    "\n",
    "        # 증강 적용 (소수 클래스만)\n",
    "        if self.augment and target in [4, 5]:\n",
    "            if np.random.rand() > 0.5:\n",
    "                image = transforms.functional.hflip(image)\n",
    "            if np.random.rand() > 0.5:\n",
    "                image = transforms.functional.adjust_brightness(image, brightness_factor=1.2)\n",
    "            if np.random.rand() > 0.5:\n",
    "                image = transforms.functional.adjust_contrast(image, contrast_factor=1.2)\n",
    "            if np.random.rand() > 0.5:\n",
    "                image = transforms.functional.rotate(image, angle=np.random.uniform(-30, 30))\n",
    "\n",
    "        # Transform 적용\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, target\n",
    "\n",
    "# 데이터 변환(transform)을 정의합니다.\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # ResNet 입력 크기에 맞춤\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 데이터셋 생성\n",
    "dataset = CustomDataset(test_data_sets, transform=transform, augment=True)\n",
    "\n",
    "# 학습 데이터와 검증 데이터로 분리 (8:2 비율)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# 데이터 로더 생성\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# ResNet50 기반 모델 정의\n",
    "class ModifiedResNet50(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ModifiedResNet50, self).__init__()\n",
    "        self.resnet = models.resnet50(pretrained=True)\n",
    "        self.resnet.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),  # Dropout 추가\n",
    "            nn.Linear(2048, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "# 출력 클래스를 데이터셋에 맞게 조정\n",
    "num_classes = len(set(meta[\"annotations\"][\"forehead_pigmentation\"] for meta in test_data_sets[\"Metadata\"].values()))  # 타겟의 고유 클래스 수 계산\n",
    "model = ModifiedResNet50(num_classes=num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "# 클래스 가중치 계산 및 CrossEntropyLoss에 적용\n",
    "class_counts = [175, 443, 163, 69, 6, 2]  # 클래스별 샘플 개수\n",
    "class_weights = torch.tensor([1.0 / count for count in class_counts], dtype=torch.float32).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)  # 손실 함수에 클래스 가중치 적용\n",
    "\n",
    "# 모델 학습 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)  # 옵티마이저\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "# Early Stopping 클래스 정의\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.best_accuracy = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_accuracy):\n",
    "        if val_accuracy > self.best_accuracy:\n",
    "            self.best_accuracy = val_accuracy\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "# Early Stopping 초기화\n",
    "early_stopping = EarlyStopping(patience=5)\n",
    "\n",
    "# 정확도 계산 함수 (한 단계 차이를 맞은 것으로 인정)\n",
    "def calculate_accuracy(loader, model):\n",
    "    model.eval()  # 평가 모드\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, targets in loader:\n",
    "            images, targets = images.to(device), targets.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += ((predicted == targets) | (torch.abs(predicted - targets) == 1)).sum().item()\n",
    "    return correct / total\n",
    "\n",
    "# 학습 루프 정의\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # 학습 모드\n",
    "    running_loss = 0.0\n",
    "    for images, targets in train_loader:\n",
    "        images, targets = images.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # 학습 및 검증 정확도 계산\n",
    "    train_accuracy = calculate_accuracy(train_loader, model)\n",
    "    val_accuracy = calculate_accuracy(val_loader, model)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss / len(train_loader):.4f}, \"\n",
    "          f\"Train Accuracy: {train_accuracy:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "    # Learning Rate Scheduler 스텝\n",
    "    scheduler.step()\n",
    "\n",
    "    # Early Stopping 체크\n",
    "    early_stopping(val_accuracy)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break\n",
    "\n",
    "print(\"모델 학습 완료!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>efficientnet_b0 사용</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 1.7825, Train Accuracy: 28.72%\n",
      "Validation Accuracy: 38.37%\n",
      "Epoch 2/20, Loss: 1.5110, Train Accuracy: 37.76%\n",
      "Validation Accuracy: 38.37%\n",
      "Epoch 3/20, Loss: 1.5181, Train Accuracy: 37.46%\n",
      "Validation Accuracy: 37.21%\n",
      "Epoch 4/20, Loss: 1.4345, Train Accuracy: 38.92%\n",
      "Validation Accuracy: 27.91%\n",
      "Epoch 5/20, Loss: 1.3348, Train Accuracy: 38.92%\n",
      "Validation Accuracy: 29.07%\n",
      "Epoch 6/20, Loss: 1.2843, Train Accuracy: 45.92%\n",
      "Validation Accuracy: 38.37%\n",
      "Epoch 7/20, Loss: 1.2658, Train Accuracy: 47.08%\n",
      "Validation Accuracy: 37.79%\n",
      "Epoch 8/20, Loss: 1.2549, Train Accuracy: 45.19%\n",
      "Validation Accuracy: 31.98%\n",
      "Epoch 9/20, Loss: 1.2213, Train Accuracy: 45.63%\n",
      "Validation Accuracy: 37.21%\n",
      "Epoch 10/20, Loss: 1.2483, Train Accuracy: 47.23%\n",
      "Validation Accuracy: 31.40%\n",
      "Epoch 11/20, Loss: 1.1777, Train Accuracy: 47.08%\n",
      "Validation Accuracy: 34.30%\n",
      "Early stopping triggered.\n",
      "학습 완료.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "from torchvision.models import efficientnet_b0\n",
    "from torchvision.transforms import functional as TF\n",
    "\n",
    "# Early Stopping 클래스 정의\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, delta=0):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.counter = 0\n",
    "\n",
    "    def __call__(self, val_accuracy):\n",
    "        score = val_accuracy\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.counter = 0\n",
    "\n",
    "# Dataset 클래스 정의 (증강 포함)\n",
    "class SkinDataset(Dataset):\n",
    "    def __init__(self, data, transform=None, augment=False):\n",
    "        self.data = data\n",
    "        self.images = data[\"Images\"]\n",
    "        self.metadata = data[\"Metadata\"]\n",
    "        self.transform = transform\n",
    "        self.augment = augment\n",
    "        self.keys = list(self.metadata.keys())  # 데이터 키 리스트\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.keys)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        key = self.keys[idx]\n",
    "        image_data = self.images[key]  # numpy.ndarray 이미지 데이터\n",
    "        metadata = self.metadata[key]  # 메타데이터\n",
    "        \n",
    "        # numpy.ndarray 이미지를 PIL 이미지로 변환\n",
    "        image = Image.fromarray(image_data)\n",
    "        \n",
    "        # 타겟 레이블 (forehead_pigmentation)\n",
    "        target = metadata[\"annotations\"][\"forehead_pigmentation\"]\n",
    "        \n",
    "        # 증강 적용 (전체 클래스)\n",
    "        if self.augment:\n",
    "            if torch.rand(1).item() > 0.5:\n",
    "                image = TF.hflip(image)\n",
    "            if torch.rand(1).item() > 0.5:\n",
    "                image = TF.adjust_brightness(image, brightness_factor=torch.rand(1).item() + 0.5)\n",
    "            if torch.rand(1).item() > 0.5:\n",
    "                image = TF.rotate(image, angle=torch.randint(-30, 30, (1,)).item())\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, target\n",
    "\n",
    "# 이미지 전처리\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Dataset 및 Train/Validation Split\n",
    "dataset = SkinDataset(test_data_sets, transform=transform, augment=True)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# 클래스 가중치 계산\n",
    "targets = [metadata[\"annotations\"][\"forehead_pigmentation\"] for metadata in test_data_sets[\"Metadata\"].values()]\n",
    "target_distribution = Counter(targets)\n",
    "total_samples = len(targets)\n",
    "class_weights = [total_samples / target_distribution[c] for c in range(6)]\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "\n",
    "# EfficientNet 모델 로드 및 수정\n",
    "model = efficientnet_b0(pretrained=True)\n",
    "model.classifier[1] = nn.Linear(model.classifier[1].in_features, 6)  # 출력 클래스 변경\n",
    "\n",
    "# Dropout 확률 설정\n",
    "for module in model.modules():\n",
    "    if isinstance(module, nn.Dropout):\n",
    "        module.p = 0.3\n",
    "\n",
    "# Weighted Loss, Optimizer 및 Learning Rate Scheduler\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "# GPU/CPU 장치 설정\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# 학습 및 검증 루프\n",
    "num_epochs = 20\n",
    "early_stopping = EarlyStopping(patience=5)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    \n",
    "    for images, targets in train_loader:\n",
    "        images, targets = images.to(device), targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_train += (predicted == targets).sum().item()\n",
    "        total_train += targets.size(0)\n",
    "    \n",
    "    train_accuracy = correct_train / total_train * 100\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader):.4f}, Train Accuracy: {train_accuracy:.2f}%\")\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    with torch.no_grad():\n",
    "        for images, targets in val_loader:\n",
    "            images, targets = images.to(device), targets.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_val += (predicted == targets).sum().item()\n",
    "            total_val += targets.size(0)\n",
    "    \n",
    "    val_accuracy = correct_val / total_val * 100\n",
    "    print(f\"Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "    \n",
    "    # 학습률 조정\n",
    "    scheduler.step()\n",
    "\n",
    "    # Early Stopping 체크\n",
    "    early_stopping(val_accuracy)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break\n",
    "\n",
    "print(\"학습 완료.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
